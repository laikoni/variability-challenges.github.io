<!DOCTYPE html>
<html lang="en">
<head>
  <title>Variability Challenges</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet" type="text/css">
  <link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet" type="text/css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script>
</head>
<body id="mainPage" data-spy="scroll" data-target=".navbar" data-offset="60">

<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>                        
      </button>
      <a class="navbar-brand" href="#mainPage"></a>
    </div>
    <div class="collapse navbar-collapse" id="myNavbar">
      <ul class="nav navbar-nav navbar-right">
        <!-- <li><a href="#intro">Intro</a></li>
		<li><a href="#edition">Editions</a></li> -->
      </ul>
    </div>
  </div>
</nav>

<div class="jumbotron text-center">
<h1>Variability Challenges</h1>
<h3>Systems and Software Variability Challenges<br/><i>The official website of the Systems and Software Product Line Conference challenge track</i></h3>
</div>

<div id="intro" class="container-fluid">
  <div class="row">
  <div class="col-sm-2"></div>
   <div class="col-sm-8" style="text-align:center">
<h2>Community</h2>
        <h4><span class="label label-info"><span class="glyphicon glyphicon glyphicon-user"></span><span class="glyphicon glyphicon glyphicon-user"></span><span class="glyphicon glyphicon glyphicon-user"></span></span></h4>
        The SPLC challenge track aims at providing the software product-line (SPL) community with a set of case studies that tackle relevant SPL problems and challenge the state of the art. The challenge track was established with SPLC 2018 in Gothenburg, initiated by Sarah Nadi, Timo Kehrer, and Thorsten Berger.<br/>
The challenge is organized in two phases every year. The first phase is the call for cases. Submitted cases will be reviewed by the challenge co-chairs to ensure that all required information is clearly described. Accepted cases will be part of the official conference proceedings. Authors of the accepted cases must attend the challenge track and participate in the discussion. The second phase is a call for solutions to both newly accepted as well as previously accepted cases. Submitted case solutions will be peer-reviewed by the challenge program committee. Accepted solutions will also be part of the official conference proceedings. Authors of accepted solutions must present their papers during the conference.<br/>
<br />This year, we are placing a special emphasis in our call for cases on the need for <b>actionable benchmarks and competition</b>, akin to those prevalent in the machine learning and SAT communities, and as developed on platforms like Kaggle. We believe that introducing such benchmarks and competition will significantly enhance the ability to compare state-of-the-art solutions and new contributions in the field of software product-line engineering. This kind of proposal should not only foster a spirit of innovation and collaboration but also provides a concrete, measurable framework for assessing the effectiveness and efficiency of new methodologies or implementations. We encourage submissions that offer well-defined, challenging, and replicable benchmarks, thereby setting the stage for a more lively and results-oriented challenge track. 
	<br/>
        You are highly encouraged to contribute to this website. For example by collecting references to challenge solutions outside the SPLC challenge track. You can propose any improvement or correction by direct editing the <a href="https://github.com/variability-challenges/variability-challenges.github.io" target="_new">github-based website</a> and creating a pull request , creating a <a href="https://github.com/variability-challenges/variability-challenges.github.io/issues/new" target="_new">github issue</a>, or just sending an email to the challenge track co-chairs.
   </div>
  </div>
  </div>
</div>

<div id="intro" class="container-fluid">
  <div class="row">
  <div class="col-sm-1"></div>
   <div class="col-sm-2" style="text-align:center">
   <i>Current SPLC</i><br/>
   <a href="https://2024.splc.net/" target="_new"><img style="width:70%" src="./files/SPLC24logo.png"></a><br/>
   <i>Challenge track co-chairs</i><br/>
   Mathieu Acher<br/>University of Rennes, FRA<br/>
   Thomas Thüm<br/>University of Ulm, GER<br/>
   </div>
    <div class="col-sm-7">
         
    <h1>SPLC 2024</h1>
         <h4><span class="label label-info">Call for <strong>Solution</strong> <strike>and Challenges</strike> is now open!</span></h4>
        <!-- <h4><span class="label label-warning">deadline: June 14, 2022</span></h4> -->
        Submission instructions: <a href="https://2024.splc.net/" target="_new">https://2024.splc.net/</a>
        <h4>Please note that the call for solutions also includes the accepted challenges of previous years (from 2018 to 2024!).</h4>
    Solutions will be included in the conference proceedings, and presented during the conference.<br/>
<!--      <b>Deadline for Challenge solutions: June 14, 2022</b><br/>           
    <h1>Challenges</h1> 
    <h3>A Benchmark for Active Learning of Variability-Intensive Systems</h3>
    <i>Shaghayegh Tavassoli, Carlos Diego Nascimento Damasceno, Mohammad Reza Mousavi and Ramtin Khosravi</i><br/>
    <a href="./2022/activelearningbenchmark/index.html" target="_new"><span class="glyphicon glyphicon-arrow-right"></span> Challenge and Solutions site</a><br/>
    Behavioral models are the key enablers ....
    -->  
	<!-- <h1>Challenges</h1> -->
	<h3>Resource Interaction Failures in Mobile Applications: A Challenge for the Software Product Line Testing Community</h3>
	<i>Euler Marinho, Fischer Ferreira, Eduardo Fernandes, João Paulo Diniz, Eduardo Figueiredo</i><br /> <a
		href="./2024/interaction_failures_mobileapp/index.html" target="_new"><span
		class="glyphicon glyphicon-arrow-right"></span>Challenge and Solutions site</a><br />
		Context: Many mobile applications run on multiple platforms with specific available resources. 
		These resources are associated with communication capabilities, sensors, and user customization. 
		Certain resource combinations imply interactions between resources that are likely to produce failures in mobile applications, 
		thereby harming the user experience. 
		Challenge: There may be a large number of resource combinations for a single mobile application. 
		Consequently, exhaustively testing resource interactions to spot failures can be very challenging. 
		However, in order to address this challenge, having robust, well-documented, 
		and publicly available datasets for mobile application testing is necessary. 
		Proposal: This paper proposes the Resource Interaction Challenge targeting mobile applications. 
		We introduce a curated dataset of 20 mobile applications with varying sizes (up to 350K lines of code) and required resources (Bluetooth, Wi-Fi, etc.). 
		Due to the shortage of sampling strategies for testing resource interactions in mobile applications, we opted for strategies commonly used for config- urable systems in general. Our dataset includes failures detected and source code metrics computed for each mobile application. Conclusion: We expect to engage both researchers and practitioners in reusing our dataset, 
		especially to propose and evaluate novel testing strategies.
	<div class="col-sm-2"></div>
  </div>
  
</div>

	<div id="intro" class="container-fluid">
		<div class="row">
			<div class="col-sm-1"></div>
			<div class="col-sm-2" style="text-align: center">
				<a href="http://2023.splc.net/" target="_new"><img
					style="width: 70%" src="./files/cropped-SPLC23logo.png"></a><br />
				<i>Challenge track co-chairs</i><br /> Angelo Gargantini University
				of Bergamo, IT <br /> Stefania Gnesi Italian National Research
				Council, IT<br />
			</div>
			<div class="col-sm-7">
				<!-- <h1>Challenges</h1> -->
				<h3>Generating Pairwise Covering Arrays for Highly Configurable
					Software Systems</h3>
				<i>Jianping Song, Qiyuan Zhao, Yibei Li, Shaowei Cai and
					Chunming Hu</i><br /> <a
					href="./2023/pairwise_covering_arrays/index.html" target="_new"><span
					class="glyphicon glyphicon-arrow-right"></span>Solutions site</a><br />
				Highly configurable software systems play crucial roles in
				real-world applications, which urgently calls for useful testing
				methods. Combinatorial interaction testing (CIT) is an effective
				methodology for detecting those faults that are triggered by the
				interaction of any t options, where t is the testing strength.
				Pairwise testing, i.e., CIT with t = 2, is known to be the most
				practical and popular CIT technique, and the pairwise covering array
				generation (PCAG) problem is the most critical problem in pairwise
				testing. Due to the practical importance of PCAG, many PCAG
				algorithms have been proposed. Unfortunately, existing PCAG
				algorithms suffer from the severe scalability problem. To this end,
				the SPLC Scalability Challenge (i.e., Product Sampling for Product
				Lines: The Scalability Challenge) has been proposed since 2019, in
				order to motivate researchers to develop practical PCAG algorithms
				for overcoming this scalability problem. In this work, we present a
				practical PCAG algorithm dubbed SamplingCA-ASF. To the best of our
				knowledge, our experiments show that SamplingCA-ASF is the first
				algorithm that can generate PCAs for Automotive02 and Linux, the two
				hardest and largest-scale instances in the SPLC Scalability
				Challenge, within reasonable time. Our experimental results indicate
				that SamplingCA-ASF can effectively alleviate the scalability
				problem in pairwise testing.
				<div class="col-sm-2"></div>
			</div>
		</div>
	<div id="intro" class="container-fluid">
		<div class="row">
			<div class="col-sm-1"></div>
			<div class="col-sm-2" style="text-align: center">
				<a href="http://2022.splc.net/" target="_new"><img
					style="width: 70%" src="./files/SPLC_2022.png"></a><br /> <i>Challenge
					track co-chairs</i><br /> Laura Semini, University of Pisa, IT<br />
				Xavier Devroey, University of Namur, BE<br />
			</div>
			<div class="col-sm-7">
				<!-- <h1>Challenges</h1> -->
				<h3>A Benchmark for Active Learning of Variability-Intensive
					Systems</h3>
				<i>Shaghayegh Tavassoli, Carlos Diego Nascimento Damasceno,
					Mohammad Reza Mousavi and Ramtin Khosravi</i><br /> <a
					href="./2022/activelearningbenchmark/index.html" target="_new"><span
					class="glyphicon glyphicon-arrow-right"></span> Challenge and
					Solutions site</a><br /> Behavioral models are the key enablers for
				behavioral analysis of Software Product Lines (SPL), including
				testing and model checking. Active model learning comes to the
				rescue when family behavioral models are non-existent or outdated. A
				key challenge on active model learning is to detect commonalities
				and variability efficiently and combine them into concise family
				models. Benchmarks and their associated metrics will play a key role
				in shaping the research agenda in this promising field and provide
				an effective means for comparing and identifying relative strengths
				and weaknesses in the forthcoming techniques. In this challenge, we
				seek benchmarks to evaluate the efficiency (e.g., learning time and
				memory footprint) and effectiveness (e.g., conciseness and accuracy
				of family models) of active model learning methods in the software
				product line context. These benchmark sets must contain the
				structural and behavioral variability models of at least one SPL.
				Each SPL in a benchmark must contain products that requires more
				than one round of model learning with respect to the basic active
				learning L* algorithm. Alternatively, tools supporting the synthesis
				of artificial benchmark models are also welcome.
				<div class="col-sm-2"></div>
			</div>
		</div>
	</div>
	<div id="intro" class="container-fluid">
		<div class="row">
			<div class="col-sm-1"></div>
			<div class="col-sm-2" style="text-align: center">
				<a href="http://www.splc2021.net/" target="_new"><img
					style="width: 70%" src="./files/SPLC_2021.svg"></a><br /> <i>Challenge
					track co-chairs</i><br /> Paul Temple, University of Namur, BE<br />
				Iris Reinhartz-Berger, University of Haifa, IL<br />
			</div>
			<div class="col-sm-7">
				<!-- <h1>Challenges</h1> -->

				<h3>Variability Fault Localization: A Benchmark</h3>
				<i>Kien-Tuan Ngo, Thu-Trang Nguyen, Son Nguyen, Hieu Dinh Vo </i><br />
				<a href="./2021/FaultLocalizationBenchmark/index.html" target="_new"><span
					class="glyphicon glyphicon-arrow-right"></span> Challenge and
					Solutions site</a><br /> Software fault localization is one of the
				most expensive, tedious, and time-consuming activities in program
				debugging. This activity becomes even much more challenging in
				Software Product Line (SPL) systems due to the variability of
				failures in SPL systems. These unexpected behaviors are caused by
				variability faults which can only be exposed under some combinations
				of system features. Although localizing bugs in non-configurable
				code has been investigated in-depth, variability fault localization
				in SPL systems still remains mostly unexplored. To approach this
				challenge, we propose a benchmark for variability fault localization
				with a large set of 1,773 buggy versions of six SPL systems and
				baseline variability fault localization performance results. Our
				hope is to engage the community to propose new and better approaches
				to the problem of variability fault localization in SPL systems. <br />
				<h3>Managing Systems Evolving in Space and Time: Four
					Challenges for Maintenance, Evolution and Composition of Variants</h3>
				<i>Gabriela Karoline Michelon, David Obermann, Wesley K. G.
					Assunção, Lukas Linsbauer, Paul Grünbacher, Alexander Egyed</i><br />

				<a href="./2021/SystemsEvolvingTimeSpace/index.html" target="_new"><span
					class="glyphicon glyphicon-arrow-right"></span> Challenge and
					Solutions site</a><br /> Software companies need to provide a large
				set of features satisfying functional and non-functional
				requirements of diverse customers, thereby leading to variability in
				space. Feature location techniques have been proposed to support
				software maintenance and evolution in space. However, so far only
				one feature location technique also analyses the evolution in time
				of system variants, which is required for feature enhancements and
				bug fixing. Specifically, existing tools for managing a set of
				systems over time do not offer proper support for keeping track of
				feature revisions, updating existing variants, and creating new
				product configurations based on feature revisions. This paper
				presents four challenges concerning such capabilities for feature
				(revision) location and composition of new product configurations
				based on feature/s (revisions). We also provide a benchmark
				containing a ground truth and support for computing metrics. We hope
				that this will motivate researchers to provide and evaluate
				tool-supported approaches aiming at managing systems evolving in
				space and time. Further, we do not limit the evaluation of
				techniques to only this benchmark: we introduce and provide
				instructions on how to use a benchmark extractor for generating
				ground truth data for other systems. We expect that the feature
				(revision) location techniques maximize information retrieval in
				terms of precision, recall, and F-score, while keeping execution
				time and memory consumption low. <br />
			</div>
			<div class="col-sm-2"></div>
		</div>
	</div>

	<div id="intro" class="container-fluid">
				<div class="row">
					<div class="col-sm-1"></div>
					<div class="col-sm-2" style="text-align: center">
						<a href="http://www.splc2020.net/" target="_new"><img
							style="width: 70%" src="./files/SPLC_2020.png"></a><br /> <i>Challenge
							track co-chairs</i><br /> José A. Galindo, University of Seville,
						Spain<br /> Lukas Linsbauer, Technische Universität Braunschweig,
						Germany<br />
					</div>
					<div class="col-sm-7">
						<!-- <h1>Challenges</h1> -->

						<h3>Testing Configurable Software Systems: The Failure
							Observation Challenge</h3>
						<i>Fischer Ferreira, Markos Viggiato, MaurÍcio Souza and
							Eduardo Figueiredo. </i><br /> <a href="./2020/Testing/index.html"
							target="_new"><span class="glyphicon glyphicon-arrow-right"></span>
							Challenge and Solutions site</a><br /> Configurable software systems
						can be adapted or configured according to a set of features to
						increase reuse and productivity. The testing process is essential
						because configurations that fail may potentially hurt user
						experience and degrade the reputation of a project. However,
						testing configurable systems is very challenging due to the number
						of configurations to run with each test, leading to a
						combinatorial explosion in the number of configurations and tests.
						Currently, several testing techniques and tools have been proposed
						to deal with this challenge, but their potential practical
						application remains mostly unexplored. To encourage the research
						area on testing configurable systems, researchers and
						practitioners should be able to try out their solutions in common
						datasets. In this paper, we propose a dataset with 30 configurable
						software systems and extensive test suits. Moreover, we report
						failures found in these systems and source code metrics to allow
						evaluating candidate solutions. We hope to engage the community
						and stimulate new and existing approaches to the problem of
						testing configurable systems. <br />
						<h3>Variability Management meets Microservices: Six
							Challenges of Re-Engineering Microservice-Based Webshops</h3>
						<i>Wesley K. G. Assunção, Jacob Krüger and Willian D. F.
							Mendonça</i><br /> <a href="./2020/Microservices/index.html"
							target="_new"><span class="glyphicon glyphicon-arrow-right"></span>
							Challenge and Solutions site</a><br /> A microservice implements a
						small unit of functionality that it provides through a network
						using lightweight protocols. So, microservices can be combined to
						fulfill tasks and implement features of a larger software system -
						resembling a variability mechanism in the context of a software
						product line (SPL). Microservices and SPLs have similar goals,
						namely facilitating reuse and customizing, but they are usually
						employed in different contexts. Any developer who has access to
						the network can provide a microservice for any task, while SPLs
						are usually intended to implement features of a single domain. Due
						to their different concepts, using microservices to implement an
						SPL or adopting SPL practices (e.g., variability management) for
						microservices is a challenging cross-area research problem.
						However, both techniques can complement each other, and thus
						tackling this problem promises benefits for organizations that
						employ either technique. In this paper, we reason on the
						importance of advancing in this direction, and sketch six concrete
						challenges to initiate research, namely (1) feature
						identification, (2) variability modeling, (3) variable
						microservice architectures, (4) interchangeability, (5) deep
						customization, and (6) re-engineering an SPL. We intend these
						challenges to serve as a starting point for future research in
						this cross-area research direction---avoiding that the concepts of
						one area are reinvented in the other. <br />

						<h3>A BDD for Linux? The Knowledge Compilation Challenge for
							Variability</h3>
						<i>Thomas Thüm</i><br /> <a href="./2020/Linux/index.html"
							target="_new"><span class="glyphicon glyphicon-arrow-right"></span>
							Challenge and Solutions site</a><br /> What is the number of valid
						configurations for Linux? How to generate uniform random samples
						for Linux? Can we create a binary decision diagram for Linux? It
						seems that the product-line community tries hard to answer such
						questions for Linux and other configurable systems. However,
						attempts are often not published due to the publication bias;
						unsuccessful attempts are not published. As a consequence,
						researchers keep trying by potentially spending redundant effort.
						<br />
					</div>
					<div class="col-sm-2"></div>
				</div>
			</div>

			<div id="intro" class="container-fluid">
				<div class="row">
					<div class="col-sm-1"></div>
					<div class="col-sm-2" style="text-align: center">
						<a href="http://www.splc2019.net/" target="_new"><img
							style="width: 70%" src="./files/SPLC_2019.png"></a><br /> <i>Challenge
							track co-chairs</i><br /> Jabier Martinez, Tecnalia, Spain<br />
						Timo Kehrer, Humboldt-Universität zu Berlin, Germany<br />
					</div>
					<div class="col-sm-7">
						<!-- <h1>Challenges</h1> -->

						<h3>Applying Product Line Engineering Concepts to Deep Neural
							Networks</h3>
						<i>Javad Ghofrani, Ehsan Kozegar, Anna Lena Fehlhaber, and
							Mohammad Divband Soorati</i><br /> <a
							href="./2019/DeepNeuralNetworks/index.html" target="_new"><span
							class="glyphicon glyphicon-arrow-right"></span> Challenge and
							Solutions site</a><br /> Deep Neural Networks (DNNs) are
						increasingly being used as a machine learning solution thanks to
						the complexity of their architecture and hyperparameters-weights.
						A drawback is the excessive demand for massive computational power
						during the training process. Not only as a whole but parts of
						neural networks can also be in charge of certain functionalities.
						We present a novel challenge in an intersection between machine
						learning and variability management communities to reuse modules
						of DNNs without further training. Let us assume that we are given
						a DNN for image processing that recognizes cats and dogs. By
						extracting a part of the network, without additional training a
						new DNN should be divisible with the functionality of recognizing
						only cats. Existing research in variability management can offer a
						foundation for a product line of DNNs composing the reusable
						functionalities. An ideal solution can be evaluated based on its
						speed, granularity of determined functionalities, and the support
						for adding variability to the network. The challenge is decomposed
						in three subchallenges: feature extraction, feature abstraction,
						and the implementation of a product line of DNNs. <br />

						<h3>Product Sampling for Product Lines: The Scalability
							Challenge</h3>
						<i>Tobias Pett, Thomas Thüm, Tobias Runge, Sebastian Krieter,
							Malte Lochau, and Ina Schaefer</i><br /> <a
							href="./2019/Sampling/index.html" target="_new"><span
							class="glyphicon glyphicon-arrow-right"></span> Challenge and
							Solutions site</a><br /> Quality assurance for product lines is
						often infeasible for each product separately. Instead, often only
						a subset of all products (i.e. a sample) is considered in testing
						such that at least the coverage of certain feature interactions is
						guaranteed. While pair-wise interaction sampling covers all
						interactions between two features, its generalization to t-wise
						interaction sampling ensures coverage for all interactions among t
						features. However, sampling for large product lines poses a
						challenge, as today’s algorithms tend to run out of memory, do not
						terminate, or produce samples, which are too large to be tested.
						To approach this challenge, we provide a set of large real-world
						feature-models with up-to 19 thousand features, which are supposed
						to be sampled. The performance of the sampling is evaluated based
						on the time and memory consumed to retrieve a sample and the
						sample size for a given coverage (i.e. t value). A well-performing
						sampling algorithm achieves full t-wise coverage, while minimizing
						all three of these properties. <br />

					</div>
					<div class="col-sm-2"></div>
				</div>
			</div>


			<div id="intro" class="container-fluid">
				<div class="row">
					<div class="col-sm-1"></div>
					<div class="col-sm-2" style="text-align: center">
						<a href="http://www.splc2018.net/" target="_new"><img
							style="width: 70%" src="./files/SPLC_2018.png"></a><br /> <i>Challenge
							track co-chairs</i><br /> Sarah Nadi, University of Alberta, Canada<br />
						Timo Kehrer, Humboldt-Universität zu Berlin, Germany<br />
					</div>
					<div class="col-sm-7">

						<h3>Apo-Games – A Case Study for Reverse Engineering
							Variability from Cloned Java Variants</h3>
						<i>Jacob Krüger, Wolfram Fenske, Thomas Thüm, Dirk Aporius,
							Gunter Saake, and Thomas Leich</i><br /> <a
							href="./2018/ApoGames/index.html" target="_new"><span
							class="glyphicon glyphicon-arrow-right"></span> Challenge and
							Solutions site</a><br /> Software-product-line engineering is an
						approach to systematically manage reusable software features and
						has been widely adopted in practice. Still, in most cases,
						organizations start with a single product that they clone and
						modify when new customer requirements arise (a.k.a.
						clone-and-own). With an increasing number of variants, maintenance
						can become challenging and organizations may consider migrating
						towards a software product line, which is referred to as
						extractive approach. While this is the most common approach in
						practice, techniques to extract variability from cloned variants
						still fall short in several regards. In particular, this accounts
						for the low accuracy of automated analyses and refactoring, our
						limited understanding of the costs involved, and the high manual
						effort. A main reason for these limitations is the lack of
						realistic case studies. To tackle this problem, we provide a set
						of cloned variants. In this paper, we characterize these variants
						and challenge the research community to apply techniques for
						reverse engineering feature models, feature location, code smell
						analysis, architecture recovery, and the migration towards a
						software product line. By evaluating solutions with the developer
						of these variants, we aim to contribute to a larger body of
						knowledge on this real-world case study.<br /> <br />

						<h3>Feature Location Benchmark with ArgoUML SPL</h3>
						<i>Jabier Martinez, Nicolas Ordoñez, Xhevahire Tërnava, Tewfik
							Ziadi, Jairo Aponte, Eduardo Figueiredo, and Marco Tulio Valente</i><br />
						<a href="./2018/ArgoUMLSPL/index.html" target="_new"><span
							class="glyphicon glyphicon-arrow-right"></span> Challenge and
							Solutions site</a><br /> Feature location is a traceability recovery
						activity to identify the implementation elements associated to a
						characteristic of a system. Besides its relevance for software
						maintenance of a single system, feature location in a collection
						of systems received a lot of attention as a first step to
						re-engineer system variants (created through clone-and-own) into a
						Software Product Line (SPL). In this context, the objective is to
						unambiguously identify the boundaries of a feature inside a family
						of systems to later create reusable assets from these
						implementation elements. Among all the case studies in the SPL
						literature, variants derived from ArgoUML SPL stands out as the
						most used one. However, the use of different settings, or the
						omission of relevant information (e.g., the exact configurations
						of the variants or the way the metrics are calculated), makes it
						difficult to reproduce or benchmark the different feature location
						techniques even if the same ArgoUML SPL is used. With the
						objective to foster the research area on feature location, we
						provide a set of common scenarios using ArgoUML SPL and a set of
						utils to obtain metrics based on the results of existing and novel
						feature location techniques.<br /> <br />

						<h3>Interoperability of Software Product Line Variants</h3>
						<i>Ferruccio Damiani, Reiner Hähnle, Eduard Kamburjan, and
							Michael Lienhardt</i><br /> <a
							href="./2018/InteroperabilitySPLVariants/index.html"
							target="_new"><span class="glyphicon glyphicon-arrow-right"></span>
							Challenge and Solutions site</a><br /> Software Product Lines are an
						established mechanism to describe multiple variants of one
						software product. Current approaches however, do not offer a
						mechanism to support the use of multiple variants from one product
						line in the same application. We experienced the need for such a
						mechanism in an industry project with German Railways where we do
						not merely model a highly variable system, but a system with
						highly variable subsystems. We present the design challenges that
						arise when software product lines have to support the use of
						multiple variants in the same application, in particular: How to
						reference multiple variants, how to manage multiple variants to
						avoid name clashes, and how to keep multiple variants
						interoperable.<br /> <br />

						<h3>Localizing Configurations in Highly-Configurable Systems</h3>
						<i>Paul Gazzillo, Ugur Koc, Thanhvu Nguyen, and Shiyi Wei</i><br />
						<a href="./2018/LocalizingConfigurations/index.html" target="_new"><span
							class="glyphicon glyphicon-arrow-right"></span> Challenge and
							Solutions site</a><br /> The complexity of configurable systems has
						grown immensely, and it is only getting more complex. Such systems
						are a challenge for software testing and maintenance, because bugs
						and other defects can and do appear in any configuration. One
						common requirement for many development tasks is to identify the
						configurations that lead to a given defect or some other program
						behavior. We distill this requirement down to a challenge
						question: given a program location in a source file, what are
						valid configurations that include the location? The key obstacle
						is scalability. When there are thousands of configuration options,
						enumerating all combinations is exponential and infeasible. We
						provide a set of target programs of increasing difficulty and
						variations on the challenge question so that submitters of all
						experience levels can try out solutions. Our hope is to engage the
						community and stimulate new and interesting approaches to the
						problem of analyzing configurations.<br /> <br />

					</div>
					<div class="col-sm-2"></div>
				</div>
			</div>

			<footer class="container-fluid text-center">
				Variability challenges and solutions repository is maintained by <a
					href="https://cs.unibg.it/gargantini/" target="_new">Angelo
					Gargantini</a> as 2023 co-chair of the challenges and solutions track.
			</footer>

			<script>
$(document).ready(function(){
  // Add smooth scrolling to all links in navbar + footer link
  $(".navbar a, footer a[href='#mainPage']").on('click', function(event) {

    // Prevent default anchor click behavior
    event.preventDefault();

    // Store hash
    var hash = this.hash;

    // Using jQuery's animate() method to add smooth page scroll
    // The optional number (900) specifies the number of milliseconds it takes to scroll to the specified area
    $('html, body').animate({
      scrollTop: $(hash).offset().top
    }, 900, function(){
   
      // Add hash (#) to URL when done scrolling (default click behavior)
      window.location.hash = hash;
    });
  });
  
  $(window).scroll(function() {
    $(".slideanim").each(function(){
      var pos = $(this).offset().top;

      var winTop = $(window).scrollTop();
        if (pos < winTop + 600) {
          $(this).addClass("slide");
        }
    });
  });
})
</script>
</body>
</html>
